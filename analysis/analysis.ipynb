{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5 = pd.read_excel(\"../data/combined_data_2point5.xlsx\")\n",
    "pricedat2 = pd.read_excel(\"../data/pricedat2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the first 137 columns\n",
    "combined_data_2point5 = combined_data_2point5.iloc[:, :137]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep rows where 'Issue' is <= 3\n",
    "# combined_data_2point5 = combined_data_2point5[combined_data_2point5['Issue'] <= 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Correct misspelled DayofWeek values\n",
    "combined_data_2point5.loc[combined_data_2point5['DayofWeek'] == 'Tueday', 'DayofWeek'] = 'Tuesday'\n",
    "combined_data_2point5.loc[combined_data_2point5['DayofWeek'] == 'Modnay', 'DayofWeek'] = 'Monday'\n",
    "\n",
    "# Categorize 'length' into 'length2'\n",
    "combined_data_2point5['length2'] = pd.cut(\n",
    "    combined_data_2point5['length'],\n",
    "    bins=[-float('inf'), 5, 15, 30, float('inf')],\n",
    "    labels=[1, 2, 3, 4]\n",
    ").astype(float)  # Ensure it's numeric\n",
    "\n",
    "# Drop specific observations by 'responseid'\n",
    "combined_data_2point5 = combined_data_2point5[~combined_data_2point5['ResponseID'].isin(['R_79wmeJJXedp5Abj', 'R_eWcombined_data_2point5zOhU3llfEHz'])]\n",
    "\n",
    "# Map Q52 to 'age'\n",
    "combined_data_2point5['age'] = combined_data_2point5['Q52'].replace({1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 6})\n",
    "\n",
    "# Categorize Q61 into 'edu'\n",
    "combined_data_2point5['edu'] = pd.cut(\n",
    "    combined_data_2point5['Q61'],\n",
    "    bins=[-float('inf'), 2, 4, float('inf')],\n",
    "    labels=[1, 2, 3]\n",
    ").astype(float)\n",
    "\n",
    "# Assign 'gender' from Q51\n",
    "combined_data_2point5['gender'] = combined_data_2point5['Q51']\n",
    "\n",
    "# Map Q64 to 'race'\n",
    "combined_data_2point5['race'] = pd.cut(\n",
    "    combined_data_2point5['Q64'],\n",
    "    bins=[-float('inf'), 1, 2, 3, float('inf')],\n",
    "    labels=[1, 2, 3, 4]\n",
    ").astype(float)\n",
    "\n",
    "# Define a mapping for Q60 to region, state, and tz\n",
    "Q60_mapping = {\n",
    "    1: ('Alabama', 3, 2), 2: ('Alaska', 4, 4), 3: ('Arizona', 4, 3), 4: ('Arkansas', 3, 2),\n",
    "    5: ('California', 4, 4), 6: ('Colorado', 4, 3), 7: ('Connecticut', 1, 1),\n",
    "    8: ('Delaware', 3, 1), 9: ('District of Columbia', 3, 1), 10: ('Florida', 3, 1),\n",
    "    11: ('Georgia', 3, 1), 12: ('Hawaii', 4, 4), 13: ('Idaho', 4, 3), 14: ('Illinois', 2, 2),\n",
    "    15: ('Indiana', 2, 1), 16: ('Iowa', 2, 2), 17: ('Kansas', 2, 2), 18: ('Kentucky', 3, 1),\n",
    "    19: ('Louisiana', 3, 2), 20: ('Maine', 1, 1), 21: ('Maryland', 3, 1), \n",
    "    22: ('Massachusetts', 1, 1), 23: ('Michigan', 2, 1), 24: ('Minnesota', 2, 2),\n",
    "    25: ('Mississippi', 3, 2), 26: ('Missouri', 2, 2), 27: ('Montana', 4, 3),\n",
    "    28: ('Nebraska', 2, 1), 29: ('Nevada', 4, 3), 30: ('New Hampshire', 1, 1),\n",
    "    31: ('New Jersey', 1, 1), 32: ('New Mexico', 4, 3), 33: ('New York', 1, 1),\n",
    "    34: ('North Carolina', 3, 1), 35: ('North Dakota', 2, 2), 36: ('Ohio', 2, 1),\n",
    "    37: ('Oklahoma', 3, 2), 38: ('Oregon', 4, 4), 39: ('Pennsylvania', 1, 1),\n",
    "    40: ('Rhode Island', 1, 1), 41: ('South Carolina', 3, 1), 42: ('South Dakota', 2, 2),\n",
    "    43: ('Tennessee', 3, 2), 44: ('Texas', 3, 2), 45: ('Utah', 4, 3), \n",
    "    46: ('Vermont', 1, 1), 47: ('Virginia', 3, 1), 48: ('Washington', 4, 4),\n",
    "    49: ('West Virginia', 3, 1), 50: ('Wisconsin', 2, 2), 51: ('Wyoming', 4, 3)\n",
    "}\n",
    "\n",
    "combined_data_2point5[['state', 'region', 'tz']] = combined_data_2point5['Q60'].map(Q60_mapping).apply(pd.Series)\n",
    "\n",
    "# Assign time of day based on 'tz' and 'StartHour'\n",
    "def assign_time_of_day(row):\n",
    "    if row['tz'] == 1:\n",
    "        if 4 <= row['StartHour'] <= 9:\n",
    "            return 'morning'\n",
    "        elif 10 <= row['StartHour'] <= 12:\n",
    "            return 'lunch'\n",
    "        elif 13 <= row['StartHour'] <= 16:\n",
    "            return 'afternoon'\n",
    "        elif 17 <= row['StartHour'] <= 19:\n",
    "            return 'earlyevening'\n",
    "        elif 20 <= row['StartHour'] <= 23:\n",
    "            return 'lateevening'\n",
    "        elif 0 <= row['StartHour'] <= 3 or row['StartHour'] == 24:\n",
    "            return 'night'\n",
    "    elif row['tz'] == 2:\n",
    "        if 5 <= row['StartHour'] <= 10:\n",
    "            return 'morning'\n",
    "        elif 11 <= row['StartHour'] <= 13:\n",
    "            return 'lunch'\n",
    "        elif 14 <= row['StartHour'] <= 17:\n",
    "            return 'afternoon'\n",
    "        elif 18 <= row['StartHour'] <= 20:\n",
    "            return 'earlyevening'\n",
    "        elif 21 <= row['StartHour'] <= 24 or row['StartHour'] == 0:\n",
    "            return 'lateevening'\n",
    "        elif 1 <= row['StartHour'] <= 4:\n",
    "            return 'night'\n",
    "    elif row['tz'] == 3:\n",
    "        if 6 <= row['StartHour'] <= 11:\n",
    "            return 'morning'\n",
    "        elif 12 <= row['StartHour'] <= 14:\n",
    "            return 'lunch'\n",
    "        elif 15 <= row['StartHour'] <= 18:\n",
    "            return 'afternoon'\n",
    "        elif 19 <= row['StartHour'] <= 21:\n",
    "            return 'earlyevening'\n",
    "        elif 22 <= row['StartHour'] <= 1:\n",
    "            return 'lateevening'\n",
    "        elif 2 <= row['StartHour'] <= 5:\n",
    "            return 'night'\n",
    "    elif row['tz'] == 4:\n",
    "        if 7 <= row['StartHour'] <= 12:\n",
    "            return 'morning'\n",
    "        elif 13 <= row['StartHour'] <= 15:\n",
    "            return 'lunch'\n",
    "        elif 16 <= row['StartHour'] <= 19:\n",
    "            return 'afternoon'\n",
    "        elif 20 <= row['StartHour'] <= 22:\n",
    "            return 'earlyevening'\n",
    "        elif 23 <= row['StartHour'] <= 2:\n",
    "            return 'lateevening'\n",
    "        elif 3 <= row['StartHour'] <= 6:\n",
    "            return 'night'\n",
    "\n",
    "combined_data_2point5['timeofday'] = combined_data_2point5.apply(assign_time_of_day, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize time-of-day columns\n",
    "combined_data_2point5['morning'] = 0\n",
    "combined_data_2point5['lunch'] = 0\n",
    "combined_data_2point5['afternoon'] = 0\n",
    "combined_data_2point5['earlyevening'] = 0\n",
    "combined_data_2point5['lateevening'] = 0\n",
    "combined_data_2point5['night'] = 0\n",
    "\n",
    "# Assign time-of-day based on `tz` and `StartHour`\n",
    "def assign_time_blocks(row):\n",
    "    if row['tz'] == 2:\n",
    "        if 5 <= row['StartHour'] <= 10:\n",
    "            row['morning'] = 1\n",
    "        elif 11 <= row['StartHour'] <= 13:\n",
    "            row['lunch'] = 1\n",
    "        elif 14 <= row['StartHour'] <= 17:\n",
    "            row['afternoon'] = 1\n",
    "        elif 18 <= row['StartHour'] <= 20:\n",
    "            row['earlyevening'] = 1\n",
    "        elif 21 <= row['StartHour'] <= 24:\n",
    "            row['lateevening'] = 1\n",
    "        elif 1 <= row['StartHour'] <= 4:\n",
    "            row['night'] = 1\n",
    "    elif row['tz'] == 3:\n",
    "        if 6 <= row['StartHour'] <= 11:\n",
    "            row['morning'] = 1\n",
    "        elif 12 <= row['StartHour'] <= 14:\n",
    "            row['lunch'] = 1\n",
    "        elif 15 <= row['StartHour'] <= 18:\n",
    "            row['afternoon'] = 1\n",
    "        elif 19 <= row['StartHour'] <= 21:\n",
    "            row['earlyevening'] = 1\n",
    "        elif row['StartHour'] in [22, 23, 24, 1]:\n",
    "            row['lateevening'] = 1\n",
    "        elif 2 <= row['StartHour'] <= 5:\n",
    "            row['night'] = 1\n",
    "    elif row['tz'] == 4:\n",
    "        if 7 <= row['StartHour'] <= 12:\n",
    "            row['morning'] = 1\n",
    "        elif 13 <= row['StartHour'] <= 15:\n",
    "            row['lunch'] = 1\n",
    "        elif 16 <= row['StartHour'] <= 19:\n",
    "            row['afternoon'] = 1\n",
    "        elif 20 <= row['StartHour'] <= 22:\n",
    "            row['earlyevening'] = 1\n",
    "        elif row['StartHour'] in [21, 22, 23, 24, 1, 2]:\n",
    "            row['lateevening'] = 1\n",
    "        elif 3 <= row['StartHour'] <= 6:\n",
    "            row['night'] = 1\n",
    "    return row\n",
    "\n",
    "combined_data_2point5 = combined_data_2point5.apply(assign_time_blocks, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1128438708.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['month'] = combined_data_2point5['Issue'].map(issue_to_month)\n"
     ]
    }
   ],
   "source": [
    "issue_to_month = {\n",
    "    1: 5, 2: 6, 3: 7, 4: 8, 5: 9, 6: 10, 7: 11, 8: 12, 9: 1,\n",
    "    10: 2, 11: 3, 12: 4, 13: 5, 14: 6, 15: 7, 16: 8, 17: 9, 18: 10,\n",
    "    19: 11, 20: 12, 21: 1, 22: 2, 23: 3, 24: 4, 25: 5, 26: 6, 27: 7,\n",
    "    28: 8, 29: 9, 30: 10, 31: 11, 32: 12, 33: 1\n",
    "}\n",
    "combined_data_2point5['month'] = combined_data_2point5['Issue'].map(issue_to_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['age'] = combined_data_2point5['Q52'].replace({1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['edu'] = pd.cut(\n",
    "    combined_data_2point5['Q61'], \n",
    "    bins=[-float('inf'), 2, 4, float('inf')],\n",
    "    labels=[1, 2, 3]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['gender'] = combined_data_2point5['Q51']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['race'] = combined_data_2point5['Q64'].apply(lambda x: 1 if x == 1 else (2 if x == 2 else (3 if x == 3 else 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1680322895.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['inc'] = pd.cut(\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['inc'] = pd.cut(\n",
    "    combined_data_2point5['Q62'],\n",
    "    bins=[-float('inf'), 2, 5, float('inf')],\n",
    "    labels=[1, 2, 3]\n",
    ").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2418350560.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['lowinc'] = (combined_data_2point5['inc'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2418350560.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['medinc'] = (combined_data_2point5['inc'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2418350560.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['hiinc'] = (combined_data_2point5['inc'] == 3).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['lowinc'] = (combined_data_2point5['inc'] == 1).astype(int)\n",
    "combined_data_2point5['medinc'] = (combined_data_2point5['inc'] == 2).astype(int)\n",
    "combined_data_2point5['hiinc'] = (combined_data_2point5['inc'] == 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age18_24'] = (combined_data_2point5['age'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age25_34'] = (combined_data_2point5['age'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age35_44'] = (combined_data_2point5['age'] == 3).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age45_54'] = (combined_data_2point5['age'] == 4).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age55_64'] = (combined_data_2point5['age'] == 5).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\910422865.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['age65p'] = (combined_data_2point5['age'] == 6).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['age18_24'] = (combined_data_2point5['age'] == 1).astype(int)\n",
    "combined_data_2point5['age25_34'] = (combined_data_2point5['age'] == 2).astype(int)\n",
    "combined_data_2point5['age35_44'] = (combined_data_2point5['age'] == 3).astype(int)\n",
    "combined_data_2point5['age45_54'] = (combined_data_2point5['age'] == 4).astype(int)\n",
    "combined_data_2point5['age55_64'] = (combined_data_2point5['age'] == 5).astype(int)\n",
    "combined_data_2point5['age65p'] = (combined_data_2point5['age'] == 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3951717409.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for value, name in [\n",
    "    (1, 'inc19'), (2, 'inc20'), (3, 'inc40'), (4, 'inc60'), (5, 'inc80'), \n",
    "    (6, 'inc100'), (7, 'inc120'), (8, 'inc140'), (9, 'inc160')\n",
    "]:\n",
    "    combined_data_2point5[name] = (combined_data_2point5['Q62'] == value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2753457134.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['hs'] = (combined_data_2point5['edu'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2753457134.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['somecoll'] = (combined_data_2point5['edu'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2753457134.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['college'] = (combined_data_2point5['edu'] == 3).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['hs'] = (combined_data_2point5['edu'] == 1).astype(int)\n",
    "combined_data_2point5['somecoll'] = (combined_data_2point5['edu'] == 2).astype(int)\n",
    "combined_data_2point5['college'] = (combined_data_2point5['edu'] == 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3051381937.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['female'] = (combined_data_2point5['Q51'] == 2).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['female'] = (combined_data_2point5['Q51'] == 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1029867607.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['white'] = (combined_data_2point5['race'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1029867607.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['black'] = (combined_data_2point5['race'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1029867607.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['otherrace'] = ((combined_data_2point5['race'] == 3) | (combined_data_2point5['race'] == 4)).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1029867607.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['hispanic'] = (combined_data_2point5['Q63'] > 1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['white'] = (combined_data_2point5['race'] == 1).astype(int)\n",
    "combined_data_2point5['black'] = (combined_data_2point5['race'] == 2).astype(int)\n",
    "combined_data_2point5['otherrace'] = ((combined_data_2point5['race'] == 3) | (combined_data_2point5['race'] == 4)).astype(int)\n",
    "combined_data_2point5['hispanic'] = (combined_data_2point5['Q63'] > 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3280711513.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['northeast'] = (combined_data_2point5['region'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3280711513.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['midwest'] = (combined_data_2point5['region'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3280711513.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['south'] = (combined_data_2point5['region'] == 3).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3280711513.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['west'] = (combined_data_2point5['region'] == 4).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['northeast'] = (combined_data_2point5['region'] == 1).astype(int)\n",
    "combined_data_2point5['midwest'] = (combined_data_2point5['region'] == 2).astype(int)\n",
    "combined_data_2point5['south'] = (combined_data_2point5['region'] == 3).astype(int)\n",
    "combined_data_2point5['west'] = (combined_data_2point5['region'] == 4).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['weightlb'] = combined_data_2point5['Q56'].clip(lower=90, upper=490).fillna(172)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['height'] = combined_data_2point5['Q57'] + 48\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['bmi'] = (combined_data_2point5['weightlb'] * 703) / (combined_data_2point5['height'] ** 2)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['underweight'] = (combined_data_2point5['bmi'] < 18.5).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['overweight'] = ((combined_data_2point5['bmi'] >= 25) & (combined_data_2point5['bmi'] < 30)).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3464316014.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['obese'] = (combined_data_2point5['bmi'] >= 30).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Adjust weight and height\n",
    "combined_data_2point5['weightlb'] = combined_data_2point5['Q56'].clip(lower=90, upper=490).fillna(172)\n",
    "combined_data_2point5['height'] = combined_data_2point5['Q57'] + 48\n",
    "\n",
    "# Calculate BMI\n",
    "combined_data_2point5['bmi'] = (combined_data_2point5['weightlb'] * 703) / (combined_data_2point5['height'] ** 2)\n",
    "combined_data_2point5['bmi'] = combined_data_2point5['bmi'].clip(lower=15, upper=40).fillna(27)\n",
    "\n",
    "# BMI categories\n",
    "combined_data_2point5['underweight'] = (combined_data_2point5['bmi'] < 18.5).astype(int)\n",
    "combined_data_2point5['overweight'] = ((combined_data_2point5['bmi'] >= 25) & (combined_data_2point5['bmi'] < 30)).astype(int)\n",
    "combined_data_2point5['obese'] = (combined_data_2point5['bmi'] >= 30).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1561155740.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['primaryshop'] = (combined_data_2point5['Q48'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1561155740.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['farmwork'] = (combined_data_2point5['Q49'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1561155740.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['kids'] = (combined_data_2point5['Q55'] == 1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['primaryshop'] = (combined_data_2point5['Q48'] == 1).astype(int)\n",
    "combined_data_2point5['farmwork'] = (combined_data_2point5['Q49'] == 1).astype(int)\n",
    "combined_data_2point5['kids'] = (combined_data_2point5['Q55'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['hsize'] = combined_data_2point5['Q54']\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\623455558.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['hsize'] = combined_data_2point5['Q54']\n",
    "\n",
    "for value in range(1, 6):\n",
    "    combined_data_2point5[f'hsize{value}'] = (combined_data_2point5['hsize'] == value).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\357369533.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['single'] = (combined_data_2point5['Q53'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\357369533.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['married'] = (combined_data_2point5['Q53'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\357369533.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['omarry'] = (combined_data_2point5['Q53'] > 2).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['single'] = (combined_data_2point5['Q53'] == 1).astype(int)\n",
    "combined_data_2point5['married'] = (combined_data_2point5['Q53'] == 2).astype(int)\n",
    "combined_data_2point5['omarry'] = (combined_data_2point5['Q53'] > 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\272065322.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['foodstamp'] = (combined_data_2point5['Q59'] == 1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['foodstamp'] = (combined_data_2point5['Q59'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3984763732.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['conservative'] = combined_data_2point5['Q65'].apply(lambda x: x if x < 6 else 3)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3984763732.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['dkideology'] = (combined_data_2point5['Q65'] == 6).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['conservative'] = combined_data_2point5['Q65'].apply(lambda x: x if x < 6 else 3)\n",
    "combined_data_2point5['dkideology'] = (combined_data_2point5['Q65'] == 6).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2413255877.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['democrat'] = (combined_data_2point5['Q66'] == 1).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2413255877.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['repub'] = (combined_data_2point5['Q66'] == 2).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2413255877.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['tea'] = (combined_data_2point5['Q66'] == 3).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2413255877.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['indep'] = (combined_data_2point5['Q66'] == 4).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\2413255877.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['oparty'] = (combined_data_2point5['Q66'] == 5).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['democrat'] = (combined_data_2point5['Q66'] == 1).astype(int)\n",
    "combined_data_2point5['repub'] = (combined_data_2point5['Q66'] == 2).astype(int)\n",
    "combined_data_2point5['tea'] = (combined_data_2point5['Q66'] == 3).astype(int)\n",
    "combined_data_2point5['indep'] = (combined_data_2point5['Q66'] == 4).astype(int)\n",
    "combined_data_2point5['oparty'] = (combined_data_2point5['Q66'] == 5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3371667187.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5['foodpois'] = (combined_data_2point5['Q14'] == 1).astype(int)\n"
     ]
    }
   ],
   "source": [
    "combined_data_2point5['foodpois'] = (combined_data_2point5['Q14'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1056184398.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)\n"
     ]
    }
   ],
   "source": [
    "day_map = {\n",
    "    'Monday': 'dow1', 'Tuesday': 'dow2', 'Wednesday': 'dow3',\n",
    "    'Thursday': 'dow4', 'Friday': 'dow5', 'Saturday': 'dow6', 'Sunday': 'dow7'\n",
    "}\n",
    "for day, column in day_map.items():\n",
    "    combined_data_2point5[column] = (combined_data_2point5['DayofWeek'] == day).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3145537243.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'long{i}'] = (combined_data_2point5['length2'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3145537243.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'long{i}'] = (combined_data_2point5['length2'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3145537243.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'long{i}'] = (combined_data_2point5['length2'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3145537243.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'long{i}'] = (combined_data_2point5['length2'] == i).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    combined_data_2point5[f'long{i}'] = (combined_data_2point5['length2'] == i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\3620911845.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 13):\n",
    "    combined_data_2point5[f'm{i}'] = (combined_data_2point5['month'] == i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1531473743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'region{i}'] = (combined_data_2point5['region'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1531473743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'region{i}'] = (combined_data_2point5['region'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1531473743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'region{i}'] = (combined_data_2point5['region'] == i).astype(int)\n",
      "C:\\Users\\schmiess\\AppData\\Local\\Temp\\ipykernel_10352\\1531473743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  combined_data_2point5[f'region{i}'] = (combined_data_2point5['region'] == i).astype(int)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    combined_data_2point5[f'region{i}'] = (combined_data_2point5['region'] == i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'madcow', 'bse', 'antibiotic', 'hormone', 'ecoli', 'salmonella', \n",
    "    'gmo', 'pinkslime', 'lftgb', 'gestcrate', 'faw', 'cages', 'clone', \n",
    "    'greengas', 'swineflu', 'bircombined_data_2point5lu'\n",
    "]\n",
    "\n",
    "# Apply labels to Q12 variables\n",
    "Q12_labels = {f'Q12_{i+1}': label for i, label in enumerate(labels)}\n",
    "combined_data_2point5 = combined_data_2point5.rename(columns=Q12_labels)\n",
    "\n",
    "# Apply labels to Q13 variables\n",
    "Q13_labels = {f'Q13_{i+1}': label for i, label in enumerate(labels)}\n",
    "combined_data_2point5 = combined_data_2point5.rename(columns=Q13_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10_labels = {\n",
    "    'Q10_1': 'finding_affordable_foods',\n",
    "    'Q10_2': 'avoiding_pesticides_hormones_antibiotics',\n",
    "    'Q10_3': 'finding_Quick_alternatives',\n",
    "    'Q10_4': 'finding_foods_for_children',\n",
    "    'Q10_5': 'losing_weight',\n",
    "    'Q10_6': 'finding_time_to_cook',\n",
    "    'Q10_7': 'avoiding_certain_nutrients'\n",
    "}\n",
    "\n",
    "combined_data_2point5 = combined_data_2point5.rename(columns=Q10_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9_labels = {\n",
    "    'Q9_1': 'plan_buy_more_beef',\n",
    "    'Q9_2': 'plan_buy_more_chicken',\n",
    "    'Q9_3': 'plan_buy_more_pork',\n",
    "    'Q9_4': 'plan_eat_out_more',\n",
    "    'Q9_5': 'expect_higher_beef_price',\n",
    "    'Q9_6': 'expect_higher_pork_price',\n",
    "    'Q9_7': 'expect_higher_chicken_price'\n",
    "}\n",
    "\n",
    "combined_data_2point5 = combined_data_2point5.rename(columns=Q9_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of renamed columns\n",
    "renamed_columns = list(Q9_labels.values())\n",
    "\n",
    "# % Disagree Flags\n",
    "for col in renamed_columns:\n",
    "    flag_name = col.replace(\"plan_\", \"disagree_plan_\").replace(\"expect_\", \"disagree_expect_\")\n",
    "    combined_data_2point5[f'{flag_name}'] = combined_data_2point5[col].apply(lambda x: 1 if x in [1, 2] else 0)\n",
    "\n",
    "# % Agree Flags\n",
    "for col in renamed_columns:\n",
    "    flag_name = col.replace(\"plan_\", \"agree_plan_\").replace(\"expect_\", \"agree_expect_\")\n",
    "    combined_data_2point5[f'{flag_name}'] = combined_data_2point5[col].apply(lambda x: 1 if x in [4, 5] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9da_labels = {\n",
    "    'Q9da_1': 'disagree_plan_buy_more_beef',\n",
    "    'Q9da_2': 'disagree_plan_buy_more_chicken',\n",
    "    'Q9da_3': 'disagree_plan_buy_more_pork',\n",
    "    'Q9da_4': 'disagree_plan_eat_out_more',\n",
    "    'Q9da_5': 'disagree_expect_higher_beef_price',\n",
    "    'Q9da_6': 'disagree_expect_higher_pork_price',\n",
    "    'Q9da_7': 'disagree_expect_higher_chicken_price'\n",
    "}\n",
    "\n",
    "Q9a_labels = {\n",
    "    'Q9a_1': 'agree_plan_buy_more_beef',\n",
    "    'Q9a_2': 'agree_plan_buy_more_chicken',\n",
    "    'Q9a_3': 'agree_plan_buy_more_pork',\n",
    "    'Q9a_4': 'agree_plan_eat_out_more',\n",
    "    'Q9a_5': 'agree_expect_higher_beef_price',\n",
    "    'Q9a_6': 'agree_expect_higher_pork_price',\n",
    "    'Q9a_7': 'agree_expect_higher_chicken_price'\n",
    "}\n",
    "\n",
    "combined_data_2point5 = combined_data_2point5.rename(columns={**Q9da_labels, **Q9a_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q4\n",
    "lo_values = {1: 0, 2: 20, 3: 40, 4: 60, 5: 80, 6: 100, 7: 120, 8: 140, 9: 160}\n",
    "hhi_values = {1: 20, 2: 39, 3: 59, 4: 79, 5: 99, 6: 119, 7: 139, 8: 159, 9: None}\n",
    "combined_data_2point5['lo'] = combined_data_2point5['Q4'].map(lo_values)\n",
    "combined_data_2point5['hhi'] = combined_data_2point5['Q4'].map(hhi_values)\n",
    "\n",
    "# For Q5\n",
    "lo1_values = lo_values  # Same mapping as lo\n",
    "hi1_values = hhi_values  # Same mapping as hhi\n",
    "combined_data_2point5['lo1'] = combined_data_2point5['Q5'].map(lo1_values)\n",
    "combined_data_2point5['hi1'] = combined_data_2point5['Q5'].map(hi1_values)\n",
    "\n",
    "# For Q7\n",
    "lo2_values = {1: None, 2: -7.5, 3: -2.5, 4: 2.5, 5: 7.5}\n",
    "hi2_values = {1: -7.5, 2: -2.5, 3: 2.5, 4: 7.5, 5: None}\n",
    "combined_data_2point5['lo2'] = combined_data_2point5['Q7'].map(lo2_values)\n",
    "combined_data_2point5['hi2'] = combined_data_2point5['Q7'].map(hi2_values)\n",
    "\n",
    "# For Q8\n",
    "lo3_values = lo2_values  # Same mapping as lo2\n",
    "hi3_values = hi2_values  # Same mapping as hi2\n",
    "combined_data_2point5['lo3'] = combined_data_2point5['Q8'].map(lo3_values)\n",
    "combined_data_2point5['hi3'] = combined_data_2point5['Q8'].map(hi3_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_flags = {\n",
    "    'Q2_1_Group': 'natlo', 'Q2_2_Group': 'tastelo', 'Q2_3_Group': 'pricelo', \n",
    "    'Q2_4_Group': 'safelo', 'Q2_5_Group': 'convenlo', 'Q2_6_Group': 'nutlo',\n",
    "    'Q2_7_Group': 'novello', 'Q2_8_Group': 'originlo', 'Q2_9_Group': 'fairlo',\n",
    "    'Q2_10_Group': 'appearlo', 'Q2_11_Group': 'envlo', 'Q2_12_Group': 'awlo'\n",
    "}\n",
    "\n",
    "high_flags = {\n",
    "    'Q2_1_Group': 'nathi', 'Q2_2_Group': 'tastehi', 'Q2_3_Group': 'pricehi', \n",
    "    'Q2_4_Group': 'safehi', 'Q2_5_Group': 'convenhi', 'Q2_6_Group': 'nuthi',\n",
    "    'Q2_7_Group': 'novelhi', 'Q2_8_Group': 'originhi', 'Q2_9_Group': 'fairhi',\n",
    "    'Q2_10_Group': 'appearhi', 'Q2_11_Group': 'envhi', 'Q2_12_Group': 'awhi'\n",
    "}\n",
    "\n",
    "# Low Flags\n",
    "for Q, flag in low_flags.items():\n",
    "    combined_data_2point5[flag] = (combined_data_2point5[Q] == 0).astype(int)\n",
    "\n",
    "# High Flags\n",
    "for Q, flag in high_flags.items():\n",
    "    combined_data_2point5[flag] = (combined_data_2point5[Q] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['nat'] = combined_data_2point5['natlo'] - combined_data_2point5['nathi']\n",
    "combined_data_2point5['taste'] = combined_data_2point5['tastelo'] - combined_data_2point5['tastehi']\n",
    "combined_data_2point5['price1'] = combined_data_2point5['pricelo'] - combined_data_2point5['pricehi']\n",
    "combined_data_2point5['safe'] = combined_data_2point5['safelo'] - combined_data_2point5['safehi']\n",
    "combined_data_2point5['conven'] = combined_data_2point5['convenlo'] - combined_data_2point5['convenhi']\n",
    "combined_data_2point5['nut'] = combined_data_2point5['nutlo'] - combined_data_2point5['nuthi']\n",
    "combined_data_2point5['novel'] = combined_data_2point5['novello'] - combined_data_2point5['novelhi']\n",
    "combined_data_2point5['origin'] = combined_data_2point5['originlo'] - combined_data_2point5['originhi']\n",
    "combined_data_2point5['fair'] = combined_data_2point5['fairlo'] - combined_data_2point5['fairhi']\n",
    "combined_data_2point5['appear'] = combined_data_2point5['appearlo'] - combined_data_2point5['appearhi']\n",
    "combined_data_2point5['env'] = combined_data_2point5['envlo'] - combined_data_2point5['envhi']\n",
    "combined_data_2point5['aw'] = combined_data_2point5['awlo'] - combined_data_2point5['awhi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['illness'] = (combined_data_2point5['Q14'] == 1).astype(int)\n",
    "combined_data_2point5['vegetarian'] = (combined_data_2point5['Q47'] == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_2point5['totlo'] = combined_data_2point5['lo'] + combined_data_2point5['lo1']\n",
    "combined_data_2point5['tothi'] = combined_data_2point5['hhi'] + combined_data_2point5['hi1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 34):\n",
    "    combined_data_2point5[f'i{i}'] = (combined_data_2point5['Issue'] == i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of Q16 to Q42 variable names\n",
    "q_vars = [f'Q{i}_1' for i in range(16, 43)]\n",
    "\n",
    "# Combine the list of variables to keep\n",
    "keep_vars = [\n",
    "    # Demographic and socioeconomic variables\n",
    "    'age', 'edu', 'gender', 'race', 'hispanic', 'lowinc', 'medinc', 'hiinc',\n",
    "    'hsize', 'kids', 'region', 'northeast', 'midwest', 'south', 'west',\n",
    "\n",
    "    # Ideological and political variables\n",
    "    'conservative', 'dkideology', 'democrat', 'repub', 'tea', 'indep', 'oparty',\n",
    "\n",
    "    # Behavioral and lifestyle variables\n",
    "    'vegetarian', 'illness', 'primaryshop', 'farmwork',\n",
    "\n",
    "    # Choice and preference variables\n",
    "    'agree_plan_buy_more_beef', 'disagree_plan_buy_more_beef',\n",
    "    # (Include other `% Agree` and `% Disagree` variables here)\n",
    "    'nat', 'taste', 'price1', 'safe', 'conven', 'nut', 'novel', 'origin',\n",
    "    'fair', 'appear', 'env', 'aw',\n",
    "\n",
    "    # Time-based and grouping variables\n",
    "    'month', 'DayofWeek', 'Issue',\n",
    "\n",
    "    # Calculated metrics\n",
    "    'bmi', 'underweight', 'overweight', 'obese',\n",
    "\n",
    "    # ResponseID\n",
    "    'ResponseID'\n",
    "] + q_vars  # Add Q16 to Q42 variables\n",
    "\n",
    "# Subset the dataframe\n",
    "cleaned_df = combined_data_2point5[keep_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv(\"../data/cleaned_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data and subset to feasible amount of obs\n",
    "cleaned_df = pd.read_csv(\"../data/cleaned_df.csv\")\n",
    "cleaned_df = cleaned_df[cleaned_df['Issue'] <= 3]\n",
    "pricedat2 = pd.read_excel(\"../data/pricedat2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat each row 81 times\n",
    "cleaned_df_long = cleaned_df.loc[cleaned_df.index.repeat(81)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'count' column\n",
    "cleaned_df_long['count'] = np.tile(np.arange(1, 82), len(cleaned_df_long) // 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'Qnum' column\n",
    "Qnum_pattern = np.tile(np.repeat(np.arange(1, 10), 9), len(cleaned_df_long) // (9 * 9))\n",
    "cleaned_df_long['Qnum'] = Qnum_pattern[:len(cleaned_df_long)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'option' column\n",
    "option_pattern = np.tile(np.arange(1, 10), len(cleaned_df_long) // 9)\n",
    "cleaned_df_long['option'] = option_pattern[:len(cleaned_df_long)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'series' column \n",
    "cleaned_df_long['series'] = np.nan  # Initialize with NaN\n",
    "cleaned_df_long.loc[cleaned_df_long['Q16_1'].notna(), 'series'] = cleaned_df_long['count']\n",
    "cleaned_df_long.loc[cleaned_df_long['Q25_1'].notna(), 'series'] = cleaned_df_long['count'] + 81\n",
    "cleaned_df_long.loc[cleaned_df_long['Q34_1'].notna(), 'series'] = cleaned_df_long['count'] + 162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter the 'Qnum' column \n",
    "cleaned_df_long.loc[cleaned_df_long['Q16_1'].notna(), 'Qnum'] = cleaned_df_long['Qnum']\n",
    "cleaned_df_long.loc[cleaned_df_long['Q25_1'].notna(), 'Qnum'] = cleaned_df_long['Qnum'] + 9\n",
    "cleaned_df_long.loc[cleaned_df_long['Q34_1'].notna(), 'Qnum'] = cleaned_df_long['Qnum'] + 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to get 'price'\n",
    "cleaned_df_long = cleaned_df_long.merge(pricedat2[['series', 'Price']], on='series', how='left')\n",
    "cleaned_df_long = cleaned_df_long.rename(columns={'Price': 'price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for ASCs\n",
    "columns = ['burger', 'steak', 'chop', 'ham', 'breast', 'wing', 'bean', 'pasta', 'none']\n",
    "for i, col in enumerate(columns):\n",
    "    cleaned_df_long[col] = (cleaned_df_long['option'] == (i + 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create choice variable\n",
    "# Initialize the 'choice' column with 0\n",
    "cleaned_df_long['choice'] = 0\n",
    "\n",
    "# Define the Question Groups and their Qnum ranges\n",
    "Question_Groups = [\n",
    "    (range(16, 25), range(1, 10)),    # Q16_1-Q24_1 corresponds to Qnum 1-9\n",
    "    (range(25, 34), range(10, 19)),  # Q25_1-Q33_1 corresponds to Qnum 10-18\n",
    "    (range(34, 43), range(19, 28))   # Q34_1-Q42_1 corresponds to Qnum 19-27\n",
    "]\n",
    "\n",
    "# Loop through each Question Group\n",
    "for Question_range, Qnum_range in Question_Groups:\n",
    "    for Q_col, Qnum in zip(Question_range, Qnum_range):\n",
    "        col_name = f\"Q{Q_col}_1\"  # Generate column names dynamically (e.g., Q16_1, Q25_1)\n",
    "        # Update 'choice' based on the conditions\n",
    "        cleaned_df_long.loc[\n",
    "            (cleaned_df_long['Qnum'] == Qnum) &  # Match Qnum\n",
    "            cleaned_df_long[col_name].notna() &  # Ensure the Question column is not missing\n",
    "            (cleaned_df_long[col_name] == cleaned_df_long['option']),  # Match option\n",
    "            'choice'\n",
    "        ] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of Q16 to Q42 variable names\n",
    "q_vars = [f'Q{i}_1' for i in range(16, 43)]\n",
    "cleaned_df_long = cleaned_df_long.drop(columns=q_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
